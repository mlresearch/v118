---
title: " Approximate Inference for Fully Bayesian Gaussian Process Regression "
abstract: " Learning in Gaussian Process models occurs through the adaptation of hyperparameters
  of the mean and the covariance function. The classical approach entails maximizing
  the marginal likelihood yielding fixed point estimates (an approach called Type
  II maximum likelihood or ML-II). An alternative learning procedure is to infer the
  posterior over hyper-parameters in a hierarchical specication of GPs we call Fully
  Bayesian Gaussian Process Regression (GPR). This work considers two approximation
  schemes for the intractable hyperparameter posterior: 1) Hamiltonian Monte Carlo
  (HMC) yielding a sampling based approximation and 2) Variational Inference (VI)
  where the posterior over hyperparameters is approximated by a factorized Gaussian
  (mean-field) or a full-rank Gaussian accounting for correlations between hyperparameters.
  We analyse the predictive performance for fully Bayesian GPR on a range of benchmark
  data sets."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lalchand20a
month: 0
tex_title: " Approximate Inference for Fully Bayesian Gaussian Process Regression "
firstpage: 1
lastpage: 12
page: 1-12
order: 1
cycles: false
bibtex_author: Lalchand, Vidhi and Rasmussen, Carl Edward
author:
- given: Vidhi
  family: Lalchand
- given: Carl Edward
  family: Rasmussen
date: 2020-02-03
address: 
publisher: PMLR
container-title: "Proceedings of The 2nd Symposium on Advances in Approximate Bayesian
  Inference"
volume: '118'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 3
pdf: http://proceedings.mlr.press/v118/lalchand20a/lalchand20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
