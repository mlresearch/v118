---
title: "Scalable Gradients and Variational Inference for\r Stochastic Differential
  Equations "
abstract: " We derive reverse-mode (or adjoint) automatic differentiation for solutions
  of stochastic differential equations (SDEs), allowing time-efficient and constant-memory
  computation of pathwise gradients, a continuous-time analogue of the reparameterization
  trick. Specifically, we construct a backward SDE whose solution is the gradient
  and provide conditions under which numerical solutions converge. We also combine
  our stochastic adjoint approach with a stochastic variational inference scheme for
  continuous-time SDE models, allowing us to learn distributions over functions using
  stochastic gradient descent. Our latent SDE model achieves competitive performance
  compared to existing approaches on time series modeling."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: li20a
month: 0
tex_title: "Scalable Gradients and Variational Inference for\r Stochastic Differential
  Equations "
firstpage: 1
lastpage: 28
page: 1-28
order: 1
cycles: false
bibtex_author: Li, Xuechen and Wong, Ting-Kam Leonard and Chen, Ricky T. Q. and Duvenaud,
  David K.
author:
- given: Xuechen
  family: Li
- given: Ting-Kam Leonard
  family: Wong
- given: Ricky T. Q.
  family: Chen
- given: David K.
  family: Duvenaud
date: 2020-02-03
address: 
publisher: PMLR
container-title: "Proceedings of The 2nd Symposium on\r Advances in Approximate Bayesian
  Inference"
volume: '118'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 2
  - 3
pdf: http://proceedings.mlr.press/v118/li20a/li20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
